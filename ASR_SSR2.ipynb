{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import argparse\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"C:/Users/syed.irfanullah/Desktop/speach/ASSR_SSR Code/gcpcri.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_file(speech_file):\n",
    "    \"\"\"Transcribe the given audio file asynchronously.\"\"\"\n",
    "    from google.cloud import speech\n",
    "    from google.cloud.speech import enums\n",
    "    from google.cloud.speech import types\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    # [START speech_python_migration_async_request]\n",
    "    with io.open(speech_file, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = types.RecognitionAudio(content=content)\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        language_code='en-US')\n",
    "\n",
    "    # [START speech_python_migration_async_response]\n",
    "    operation = client.long_running_recognize(config, audio)\n",
    "    # [END speech_python_migration_async_request]\n",
    "\n",
    "    print('Waiting for operation to complete...')\n",
    "    response = operation.result(timeout=90)\n",
    "\n",
    "    # Each result is for a consecutive portion of the audio. Iterate through\n",
    "    # them to get the transcripts for the entire audio file.\n",
    "    for result in response.results:\n",
    "        # The first alternative is the most likely one for this portion.\n",
    "        print(u'Transcript: {}'.format(result.alternatives[0].transcript))\n",
    "        print('Confidence: {}'.format(result.alternatives[0].confidence))\n",
    "    # [END speech_python_migration_async_response]\n",
    "# [END speech_transcribe_async]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for operation to complete...\n",
      "Transcript: IEEE content should be approximately one minute to make a single request\n",
      "Confidence: 0.8337977528572083\n",
      "Transcript:  I miss type of request\n",
      "Confidence: 0.628308117389679\n"
     ]
    }
   ],
   "source": [
    " transcribe_file(\"irfanenglish.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_file_with_auto_punctuation(path):\n",
    "    \"\"\"Transcribe the given audio file with auto punctuation enabled.\"\"\"\n",
    "    # [START speech_transcribe_auto_punctuation]\n",
    "    from google.cloud import speech\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    # path = 'resources/commercial_mono.wav'\n",
    "    with io.open(path, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = speech.types.RecognitionAudio(content=content)\n",
    "    config = speech.types.RecognitionConfig(\n",
    "        encoding=speech.enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        language_code='en-US',\n",
    "        # Enable automatic punctuation\n",
    "        enable_automatic_punctuation=True)\n",
    "\n",
    "    response = client.recognize(config, audio)\n",
    "\n",
    "    for i, result in enumerate(response.results):\n",
    "        alternative = result.alternatives[0]\n",
    "        print('-' * 20)\n",
    "        print('First alternative of result {}'.format(i))\n",
    "        print('Transcript: {}'.format(alternative.transcript))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "First alternative of result 0\n",
      "Transcript: IEEE content should be approximately one minute to make a single request.\n",
      "--------------------\n",
      "First alternative of result 1\n",
      "Transcript:  I miss type of request.\n"
     ]
    }
   ],
   "source": [
    " transcribe_file_with_auto_punctuation(\"irfanenglish.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_file_with_enhanced_model(path):\n",
    "    \"\"\"Transcribe the given audio file using an enhanced model.\"\"\"\n",
    "    # [START speech_transcribe_enhanced_model]\n",
    "    import io\n",
    "\n",
    "    from google.cloud import speech\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    # path = 'resources/commercial_mono.wav'\n",
    "    with io.open(path, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = speech.types.RecognitionAudio(content=content)\n",
    "    config = speech.types.RecognitionConfig(\n",
    "        encoding=speech.enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        language_code='ur-PK',\n",
    "        # Enhanced models are only available to projects that\n",
    "        # opt in for audio data collection.\n",
    "        use_enhanced=True,\n",
    "        # A model must be specified to use enhanced model.\n",
    "        model='phone_call')\n",
    "\n",
    "    response = client.recognize(config, audio)\n",
    "\n",
    "    for i, result in enumerate(response.results):\n",
    "        alternative = result.alternatives[0]\n",
    "        print('-' * 20)\n",
    "        print('First alternative of result {}'.format(i))\n",
    "        print('Transcript: {}'.format(alternative.transcript))\n",
    "    # [END speech_transcribe_enhanced_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "First alternative of result 0\n",
      "Transcript: hello and my disco what are you going to be settlement going okay thank you\n"
     ]
    }
   ],
   "source": [
    " transcribe_file_with_enhanced_model(\"irfanurdu.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_file_with_word_time_offsets(speech_file):\n",
    "    \"\"\"Transcribe the given audio file synchronously and output the word time\n",
    "    offsets.\"\"\"\n",
    "    from google.cloud import speech\n",
    "    from google.cloud.speech import enums\n",
    "    from google.cloud.speech import types\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    with io.open(speech_file, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = types.RecognitionAudio(content=content)\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        language_code='en-US',\n",
    "        enable_word_time_offsets=True)\n",
    "\n",
    "    response = client.recognize(config, audio)\n",
    "\n",
    "    for result in response.results:\n",
    "        alternative = result.alternatives[0]\n",
    "        print(u'Transcript: {}'.format(alternative.transcript))\n",
    "\n",
    "        for word_info in alternative.words:\n",
    "            word = word_info.word\n",
    "            start_time = word_info.start_time\n",
    "            end_time = word_info.end_time\n",
    "            print('Word: {}, start_time: {}, end_time: {}'.format(\n",
    "                word,\n",
    "                start_time.seconds + start_time.nanos * 1e-9,\n",
    "                end_time.seconds + end_time.nanos * 1e-9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_file_with_diarization():\n",
    "    \"\"\"Transcribe the given audio file synchronously with diarization.\"\"\"\n",
    "    # [START speech_transcribe_diarization_beta]\n",
    "    from google.cloud import speech_v1p1beta1 as speech\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    speech_file = 'ali.wav'\n",
    "\n",
    "    with open(speech_file, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = speech.types.RecognitionAudio(content=content)\n",
    "\n",
    "    config = speech.types.RecognitionConfig(\n",
    "        encoding=speech.enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "    \n",
    "        language_code='ur-PK',\n",
    "        enable_speaker_diarization=True,\n",
    "        diarization_speaker_count=2)\n",
    "\n",
    "    print('Waiting for operation to complete...')\n",
    "    response = client.recognize(config, audio)\n",
    "\n",
    "    # The transcript within each result is separate and sequential per result.\n",
    "    # However, the words list within an alternative includes all the words\n",
    "    # from all the results thus far. Thus, to get all the words with speaker\n",
    "    # tags, you only have to take the words list from the last result:\n",
    "    result = response.results[-1]\n",
    "\n",
    "    words_info = result.alternatives[0].words\n",
    "\n",
    "    # Printing out the output:\n",
    "    for word_info in words_info:\n",
    "        print(\"word: '{}', speaker_tag: {}\".format(word_info.word,\n",
    "                                                   word_info.speaker_tag))\n",
    "    # [END speech_transcribe_diarization_beta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irfan Syed\n"
     ]
    }
   ],
   "source": [
    "print(hello.get_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
